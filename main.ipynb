{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark ile basit bir sekilde dataFrame olusturup sql sorgulariyla gosterme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 20:59:23 WARN Utils: Your hostname, icecream resolves to a loopback address: 127.0.1.1; using 192.168.1.105 instead (on interface wlo1)\n",
      "23/04/12 20:59:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/12 20:59:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------------+\n",
      "|age|isGraduated|jobStartDate|\n",
      "+---+-----------+------------+\n",
      "| 34|       true|  2006-01-01|\n",
      "| 33|       true|  1980-01-10|\n",
      "| 37|      false|        null|\n",
      "+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col \n",
    "from pyspark.sql.types import StringType, BooleanType, DateType\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType , FloatType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataFrame example 3\").getOrCreate()\n",
    "columns = [\"firstname\", \"age\", \"jobStartDate\", \"isGraduated\", \"gender\", \"salary\"]\n",
    "data = [(\"James\", 34, \"2006-01-01\", \"true\", \"M\", 3000.60), (\"Michael\", 33, \"1980-01-10\", \"true\", \"F\", 3300.80), (\"Robert\", 37, \"06-01-1992\", \"false\", \"M\", 5000.50)]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "df2 = df.withColumn(\"age\", col(\"age\").cast(StringType())).withColumn(\"isGraduated\", col(\"isGraduated\").cast(BooleanType())).withColumn(\"jobStartDate\", col(\"jobStartDate\").cast(DateType()))\n",
    "\n",
    "df3 = df2.selectExpr(\"cast(age as int) age\", \"cast(isGraduated as string) isGraduated\", \"cast(jobStartDate as string) jobStartDate\")\n",
    "df3.createOrReplaceTempView(\"my_temp_view\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM my_temp_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- jobStartDate: date (nullable = true)\n",
      " |-- isGraduated: boolean (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "Code is Here : 1\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- isGraduated: string (nullable = true)\n",
      " |-- jobStartDate: string (nullable = true)\n",
      "\n",
      "+---+-----------+------------+\n",
      "|age|isGraduated|jobStartDate|\n",
      "+---+-----------+------------+\n",
      "|34 |true       |2006-01-01  |\n",
      "|33 |true       |1980-01-10  |\n",
      "|37 |false      |null        |\n",
      "+---+-----------+------------+\n",
      "\n",
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- isGraduated: boolean (nullable = true)\n",
      " |-- jobStartDate: date (nullable = true)\n",
      "\n",
      "+---+-----------+------------+\n",
      "|age|isGraduated|jobStartDate|\n",
      "+---+-----------+------------+\n",
      "|34 |true       |2006-01-01  |\n",
      "|33 |true       |1980-01-10  |\n",
      "|37 |false      |null        |\n",
      "+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe'deki sütunların veri tiplerini değiştirme işlemi\n",
    "df2 = df.withColumn(\"age\", col(\"age\").cast(StringType())) \\\n",
    "        .withColumn(\"isGraduated\", col(\"isGraduated\").cast(BooleanType())) \\\n",
    "        .withColumn(\"jobStartDate\", col(\"jobStartDate\").cast(DateType()))\n",
    "\n",
    "# dataframe'in şemasını yazdırma\n",
    "df2.printSchema()\n",
    "print(\"Code is Here : 1\")\n",
    "\n",
    "# sütunları seçme ve veri tiplerini değiştirme işlemi\n",
    "df3 = df2.selectExpr(\"cast(age as int) age\", \"cast(isGraduated as string) isGraduated\", \"cast(jobStartDate as string) jobStartDate\")\n",
    "\n",
    "# dataframe'in şemasını yazdırma\n",
    "df3.printSchema()\n",
    "\n",
    "# dataframe'i gösterme\n",
    "df3.show(truncate=False)\n",
    "\n",
    "# dataframe'i temporary view olarak kaydetme\n",
    "df3.createOrReplaceTempView(\"CastExample\")\n",
    "\n",
    "# SQL sorgusu ile temporary view'den yeni bir dataframe oluşturma ve veri tiplerini değiştirme işlemi\n",
    "df4 = spark.sql(\"SELECT STRING(age), BOOLEAN(isGraduated), DATE(jobStartDate) FROM CastExample\")\n",
    "\n",
    "# dataframe'in şemasını yazdırma\n",
    "df4.printSchema()\n",
    "\n",
    "# dataframe'i gösterme\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F = Female ve M = Male olarak bu ikisine uymayanlarida NA olarak Gosterme ve Maaslarini 3 katina cikarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+------+----------+---------+\n",
      "|first_name|last_name|gender|salary|genderType|newSalary|\n",
      "+----------+---------+------+------+----------+---------+\n",
      "|     James|    Smith|     M|  3000|      male|     9000|\n",
      "|      Anna|     Rose|     F|  4100|    female|    12300|\n",
      "|    Robert| Williams|    NA|  6200|        NA|    18600|\n",
      "|      null|      Rob|     F|  6200|    female|    18600|\n",
      "+----------+---------+------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "newData = [('James', 'Smith', 'M', 3000),\n",
    "        ('Anna', 'Rose', 'F', 4100),\n",
    "        ('Robert', 'Williams', 'NA', 6200),\n",
    "        (None, 'Rob', 'F', 6200)]\n",
    "\n",
    "newColumns = [\"first_name\", \"last_name\", \"gender\", \"salary\"]\n",
    "\n",
    "myDf = spark.createDataFrame(data=newData, schema=newColumns)\n",
    "\n",
    "myDf = myDf.withColumn(\"genderType\", when(myDf[\"gender\"] == \"M\", \"male\")\n",
    ".when(myDf[\"gender\"] == \"F\", \"female\")\n",
    ".otherwise(\"NA\"))\n",
    "\n",
    "myDf = myDf.withColumn(\"newSalary\", myDf[\"salary\"] * 3)\n",
    "\n",
    "myDf.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yas 20 den buyuk erkek ve abc universitesine giden kisileri gosterme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+---+--------+\n",
      "|    Ad| Soyad|            Okul|Yas|Cinsiyet|\n",
      "+------+------+----------------+---+--------+\n",
      "|   Ali|Yılmaz|ABC Üniversitesi| 22|   Erkek|\n",
      "|Mehmet|Öztürk|ABC Üniversitesi| 21|   Erkek|\n",
      "| Ahmet| Demir|ABC Üniversitesi| 23|   Erkek|\n",
      "+------+------+----------------+---+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schoolData = [(\"Ali\", \"Yılmaz\", \"ABC Üniversitesi\", 22, \"Erkek\"), (\"Ayşe\", \"Kara\", \"DEF Üniversitesi\", 19, \"Kadın\"), (\"Mehmet\", \"Öztürk\", \"ABC Üniversitesi\", 21, \"Erkek\"), (\"Zeynep\", \"Aksoy\", \"GHI Üniversitesi\", 20, \"Kadın\"), (\"Ahmet\", \"Demir\", \"ABC Üniversitesi\", 23, \"Erkek\")]\n",
    "schoolSchema = StructType([ StructField(\"Ad\", StringType(), True), StructField(\"Soyad\", StringType(), True), StructField(\"Okul\", StringType(), True), StructField(\"Yas\", IntegerType(), True), StructField(\"Cinsiyet\", StringType(), True) ])\n",
    "\n",
    "schoolDf = spark.createDataFrame(data=schoolData, schema=schoolSchema)\n",
    "\n",
    "selectedData = schoolDf.filter((col('Yas') > 20) & (col('Cinsiyet') == \"Erkek\") & (col(\"Okul\") == \"ABC Üniversitesi\")).select(\"*\")\n",
    "\n",
    "selectedData.show()\n",
    "selectedData.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yas 20 - 25 arasi , ABC universitesi , erkek veya kadin , not > 80 den buyuk olucak sekilde olanlari gosteriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+---+--------+----+\n",
      "|    Ad| Soyad|            Okul|Yas|Cinsiyet| Not|\n",
      "+------+------+----------------+---+--------+----+\n",
      "|   Ali|Yılmaz|ABC Üniversitesi| 22|   Erkek|85.5|\n",
      "|  Ayşe|  Kara|DEF Üniversitesi| 19|   Kadın|78.0|\n",
      "|Mehmet|Öztürk|ABC Üniversitesi| 21|   Erkek|89.5|\n",
      "|Zeynep| Aksoy|GHI Üniversitesi| 20|   Kadın|91.0|\n",
      "| Ahmet| Demir|ABC Üniversitesi| 23|   Erkek|76.5|\n",
      "+------+------+----------------+---+--------+----+\n",
      "\n",
      "+------+------+----------------+---+--------+----+\n",
      "|    Ad| Soyad|            Okul|Yas|Cinsiyet| Not|\n",
      "+------+------+----------------+---+--------+----+\n",
      "|   Ali|Yılmaz|ABC Üniversitesi| 22|   Erkek|85.5|\n",
      "|Mehmet|Öztürk|ABC Üniversitesi| 21|   Erkek|89.5|\n",
      "+------+------+----------------+---+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schoolData = [(\"Ali\", \"Yılmaz\", \"ABC Üniversitesi\", 22, \"Erkek\", 85.5), (\"Ayşe\", \"Kara\", \"DEF Üniversitesi\", 19, \"Kadın\", 78.0), (\"Mehmet\", \"Öztürk\", \"ABC Üniversitesi\", 21, \"Erkek\", 89.5), (\"Zeynep\", \"Aksoy\", \"GHI Üniversitesi\", 20, \"Kadın\", 91.0), (\"Ahmet\", \"Demir\", \"ABC Üniversitesi\", 23, \"Erkek\", 76.5)]\n",
    "schoolSchema = StructType([ StructField(\"Ad\", StringType(), True), StructField(\"Soyad\", StringType(), True), StructField(\"Okul\", StringType(), True), StructField(\"Yas\", IntegerType(), True), StructField(\"Cinsiyet\", StringType(), True), StructField(\"Not\", FloatType(), True) ])\n",
    "\n",
    "schoolDf = spark.createDataFrame(data=schoolData , schema=schoolSchema)\n",
    "\n",
    "schoolDf.show()\n",
    "\n",
    "selectedData = schoolDf.filter((col(\"Okul\") == \"ABC Üniversitesi\") & ((col(\"Cinsiyet\") == \"Erkek\") | (col(\"Cinsiyet\") == \"Kadın\")) & (col(\"Yas\").between(20, 25)) & (col(\"Not\") > 80)).select(\"*\")\n",
    "\n",
    "selectedData.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
